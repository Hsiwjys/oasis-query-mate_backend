chunking:
  max_chunk_size: 200  # words
  overlap: 0.2         # 20% overlap between chunks
embedding:
  model: "BAAI/bge-base-en-v1.5"
retrieval:
  vector_top_k: 20
  bm25_top_k: 20
  rerank_top_k: 3
  reranker_model: "cross-encoder/ms-marco-MiniLM-L-6-v2"